(全称)Log-structured merge-tree 

[参考链接](https://www.cnblogs.com/bonelee/p/6244810.html)

## 代表DB

代表数据库：nessDB、leveldb、hbase等

## 核心思想
核心思想的核心就是放弃部分读能力，换取写入的最大化能力。LSM Tree ，这个概念就是结构化合并树的意思，它的核心思路其实非常简单，就是假定内存足够大，因此`不需要每次有数据更新就必须将数据写入到磁盘中，而可以先将最新的数据驻留在内存中，等到积累到最后多之后，再使用归并排序的方式将内存内的数据合并追加到磁盘队尾`(因为所有待排序的树都是有序的，可以通过合并排序的方式快速合并到一起)。

日志结构的合并树（LSM-tree）是一种基于硬盘的数据结构，与B-tree相比，能显著地减少硬盘磁盘臂的开销，并能在较长的时间提供对文件的高速插入（删除）。然而LSM-tree在某些情况下，特别是`在查询需要快速响应时性能不佳`。通常LSM-tree适用于索引插入比检索更频繁的应用系统。

磁盘的技术特性:对磁盘来说，能够最大化的发挥磁盘技术特性的使用方式是:一次性的读取或写入固定大小的一块数据，并尽可能的减少随机寻道这个操作的次数。

## B+ 缺点

B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，但做范围查询时，会产生大量读随机IO。

对于大量的随机写也一样，举一个插入key跨度很大的例子，如7->1000->3->2000 ... 新插入的数据存储在磁盘上相隔很远，`会产生大量的随机写IO`.

## LSM树

为了克服B+树的弱点，HBase引入了LSM树的概念，即Log-Structured Merge-Trees。

为了更好的说明LSM树的原理，下面举个比较极端的例子：

现在假设有1000个节点的随机key，对于磁盘来说，肯定是把这1000个节点顺序写入磁盘最快，但是这样一来，读就悲剧了，因为key在磁盘中完全无序，每次读取都要全扫描；

那么，为了让读性能尽量高，数据在磁盘中必须得有序，这就是B+树的原理，但是写就悲剧了，因为会产生大量的随机IO，磁盘寻道速度跟不上。

LSM树本质上就是在读写之间取得平衡，和B+树相比，`它牺牲了部分读性能，用来大幅提高写性能`。

## 原理
它的原理是把一颗大树拆分成N棵小树， 它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历所有的小树，但在每颗小树内部数据是有序的。

![LSM](../images/lsm-1.png)



以上就是LSM树最本质的原理，有了原理，再看具体的技术就很简单了。

1）首先说说为什么要有WAL（Write Ahead Log），很简单，因为数据是先写到内存中，如果断电，内存中的数据会丢失，因此为了保护内存中的数据，`需要在磁盘上先记录logfile`，当内存中的数据flush到磁盘上时，就可以抛弃相应的Logfile。

2）什么是memstore, storefile？很简单，上面说过，LSM树就是一堆小树，在内存中的小树即memstore，每次flush，内存中的memstore变成磁盘上一个新的storefile。

3）为什么会有compact？很简单，随着小树越来越多，读的性能会越来越差，因此需要在适当的时候，对磁盘中的小树进行merge，多棵小树变成一颗大树。

## 例子
LSM Tree弄了很多个小的有序结构，比如每m个数据，在内存里排序一次，下面100个数据，再排序一次……这样依次做下去，就可以获得N/m个有序的小的有序结构。

在查询的时候，因为不知道这个数据到底是在哪里，所以就从最新的一个小的有序结构里做二分查找，找得到就返回，找不到就继续找下一个小有序结构，一直到找到为止。

很容易可以看出，这样的模式，读取的时间复杂度是(N/m)*log2N 。读取效率是会下降的。

这就是最本来意义上的LSM tree的思路。那么这样做，性能还是比较慢的，于是需要再做些事情来提升，怎么做才好呢？

## LSM Tree优化方式：

a、Bloom filter: 就是个带随即概率的`bitmap`,可以快速的告诉你，某一个小的有序结构里有没有指定的那个数据的。于是就可以不用二分查找，而只需简单的计算几次就能知道数据是否在某个小集合里啦。效率得到了提升，但付出的是空间代价。

b、compact:小树合并为大树:因为小树他性能有问题，所以要有个进程不断地将小树合并到大树上，这样大部分的老数据查询也可以直接使用log2N的方式找到，不需要再进行(N/m)*log2n的查询
 


## 应用场景

日志结构的合并树（LSM-tree）是一种基于硬盘的数据结构，与B-tree相比，能显著地减少硬盘磁盘臂的开销，并能在较长的时间提供对文件的高速插入（删除）。然而LSM-tree在某些情况下，特别是在查询需要快速响应时性能不佳。通常LSM-tree适用于索引插入比检索更频繁的应用系统。


---
## 其他

大量的随机写，导致B族树在数据很大时，出现大量磁盘IO，导致速度越来越慢，lsmtree是怎么解决这个问题的：

1. 尽可能减少写磁盘次数；

2. 即便写磁盘，也是尽可能顺序写；

方法：

1. 对数据，按key划分为若干level；

每一个level对应若干文件，包括存在于内存中和落盘了的；

文件内key都是有序的，同级的各个文件之间，一般也有序

如leveldb/rocksdb，level0对应于内存中的数据(0.sst)，后面的依次是1、2、3、...的各级文件(默认到level6级)

2. 写时，先写对应于内存的最低level的文件；这是之所以写的快的一个重要原因

存在于内存的数据，也是被持久化的以防丢失；

存在于内存的数据，到达一定大小后，被合并到下一级文件落盘；

3、落盘后的各级文件，也会定期进行排序加合并(compact)，合并后数据进入下一层level；

这样的写入操作，大多数的写，都是对一个磁盘页顺序的写，或者申请新磁盘页写，而不再是随机写

总结lsmtree的写为什么快的两大原因：

1、每次写，都是在写内存；

2、定期合并写入磁盘，产生的写都是按key顺序写，而不是随机查找key再写；


核心思想的核心就是放弃部分读能力，换取写入的最大化能力。LSM Tree ，这个概念就是结构化合并树的意思，它的核心思路其实非常简单，就是假定内存足够大，因此不需要每次有数据更新就必须将数据写入到磁盘中，而可以先将最新的数据驻留在磁盘中，等到积累到最后多之后，再使用归并排序的方式将内存内的数据合并追加到磁盘队尾(因为所有待排序的树都是有序的，可以通过合并排序的方式快速合并到一起)。

