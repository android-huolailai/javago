
本文笔记 依赖 老钱的 Redis深度探险

# 基础

## string

最大长度 512M,小于 1M 加倍扩容 现有，大于 1M 扩容 1M

可以批量读写 

SDS 预分配 惰性回收

```
// 单次读写
set name houzhenguo
get name
// 批量读写
mset name1 zhangsan name2 lisi name3 wangwu
mget name1 name2 name3

// 过期时间 
expire name 5 // 5秒过期
// setnx

set age 5
incrby age -5
```

## list

相当于 Java 中的linkedlist 是链表而不是数组

用于做异步队列使用 , 使用 index  相关的操作要慎重，因为 会遍历链表。

快速列表：在数据元素较少的时候使用 ziplist ，分配的是一块连续的内存。

quicklist 就是 ziplist 结合连接起来。

```
rpush books java python
lpop books
```

## hash

字典，数组 + 链表 。 rehash 与 hashMap不同。

渐进式 rehash 。 保留新旧 两个 hash结构，查询时候会同时 查询两个 hash结构，而后在后续的定时
任务中以及 hash的子指令中，在后续的定时任务以及 hash 的子指令中，循序渐进的将 旧的 hash的内容
一点点迁移到新的 hash结构中。当hash 移除最后的元素之后，该数据结构会被自动回收。

hash 可以用来存储用户的信息，如果存储 字符串的话，反序列化会耗费网络流量。

```
hset books java "think in java"
hget books java
```

## Set

去重的功能。

## ZSet

字典，保证唯一性。 score ,内部跳跃表的实现。zset 可以用来存储粉丝列表，key为 id,score为 粉丝关注的事件

跳跃表的优点就是 比链表 查询比较快，定位。

随机分层。

## 容器的规则

1. 没有的时候创建，没有元素的时候回收。
2. 过期 以对象为单位。比如 一个 hash 结构的过期是整个 hash对象的过期，而不是其中的某个 子 key.

# 应用
## 分布式锁

重入锁的问题

锁超时的问题

我并不觉得 redis 实现分布式锁 好，建议还是 zk

获取锁失败 

1. 抛出异常
2. sleep  重试
3. 将请求转移到延迟队列，一会儿再试

## 延时队列

rpush lpop 实现 延迟队列

轮询，sleep 1 s 避免 pop 队列为空的时候一直轮询。 

替代方案： blpop/ brpop -> blocking pop

空先连接断开，注意 捕获异常重试。




## 位图

应用场景： 可以记录 每个用户 365 天签到的记录 ，1 为 签到 0 为 未签到
这样的存储 节省内存资源

## HyperLogLog  

统计 UV,用户访问量，可以使用 set，最后求 set的size。
但是对于 数据量特别大，几千万 上亿的时候，可能对于 UV的数值并不要求特别的精确，可以使用 pfadd

## BloomFilter

用户 读取过的新闻，推送的时候不能再次推送了。这个时候怎么做？

误判率。结果显示存在时候，它有可能不存在。结果显示不存在，它一定不存在。

需要安装插件。

爬虫 URL 的去重

## 限流

## 地图

附近的人 ，GeoHash算法。将 地球 映射到 二维平面，将 二维平面 编码成为 一维线性的。set score

地图的Redis 单独部署，最好是可以按照 城市划分。

## scan

可以有限制的匹配 某些key 

## PipLine

将 write read write read -> write write read  read

## Redis 事务

redis的事务 因为是单线程的，所以仅仅满足事务的隔离性。

Redis 的事务 比较简单，不像 关系型 数据库那样。

也不支持原子性，中间发生错误之后还是会继续的执行。

redis 的事务更像是 执行一组命令，multi,exec

redis 的事务将 指令 缓存在 服务器的一个事务队列中，服务器一旦受到 exec 指令，才开始执行事务队列。

## 优化

使用 pipline 将多个命令组合成为一个命令，可以避免IO的操作。

## Watch

也是 事务相关的操作。

Redis 存储账户余额数据，现在有两个并发的客户端要对余额进行修改操作。

将某个数 提取出来 处理 ，然后再写回。这样就会出现并发的问题。我们可以使用 分布式锁来解决，但是这是一种悲观的方式。如何使用 乐观的方式进行解决呢。

Redis 提供了 watch 机制。它是一种乐观锁。watch 机制就是在事务开始之前 盯住 1 个 或者多个 关键变量，当事务执行时候，就是服务器 收到 exec 指令要顺序 执行缓存的事务队列时候， Redis会检查关键变量自watch 之后是否被修改了，如果被修改了，，返回 nil,告知客户端执行失败，这时候客户端选择重试。


redis 为什么不支持 事务回滚？

redis事务在执行的过程中，不会处理其它命令，而是等所有命令都执行完后，再处理其它命令（满足隔离性）

只有 redis 语法问题的时候才会出错，这种情况是程序 bug。回滚不能处理成功。

## Redis 内存处理

1. 32bit vs 64bit

Redis 使用 32bit进行编译，内存少一半

## ziplist

小对象的压缩。举例： 用数组代替 hashMap。

压缩列表是一个紧凑的字节数组结构。每个元素都是紧挨着的。




## 主从同步


一句话概括 CAP理论：网络分区发生时，一致性可用性 难两全。

Redis 主从数据是异步同步的，所以 Redis 系统并不满足 一致性的要求。

当客户端 在 Redis 的主节点修改了数据之后，立即返回。即使在主从网络断开的情况下，主节点依旧可以对外提供修改服务。所以 Redis 满足可用性。

Redis 保证最终一致性。从节点会努力追赶主节点。最终从节点，主节点的状态保持一致。


### 增量同步

Redis 同步的是指令流。主节点会将 修改型的指令 记录在本地的内存 buffer中。

然后将 buffer中的指令同步到从节点。从节点一遍执行同步指令，一遍反馈偏移量。

buffer 是有限的，是环形的。如果数组满了，就会从头 开始 覆盖前面的内容。

### 快照同步

快照同步是一个非常耗时的操作，需要 bgsave.将当前内存中的数据全部快照到磁盘中，然后将 快照的内容全部传送到从节点。 快照复制结束之后，进行增量的同步。期间，会把 操作存储在 buff 中，如果 buff太小或者 快照同步时间太长，那么可能会被覆盖。然后不得已又得同步快照，等等陷入死循环。‘

### 无盘复制

就是不用生成 快照文件了。而是一边遍历 内存，一边发送 socket

从节点接收到之后还是先将内容存储到磁盘文件中，再进行一次性加载，在加载之前会清空内存。

## Sentinel

主从模式的集群属于 高并发，那么 Sentinel 就属于 高可用范畴了。

我们可以将 Redis Sentinel 集群 看成是一个 zk集群。它是高可用心脏。一般是由3-5个节点组成。它负责 持续监控主从节点的健康。当主节点挂掉时，自动选择一个最优的从节点切换为 主节点。


客户端来连接集群的时候，会首先连接 sentiel,通过 sentiel 来查询主节点为地址。然后再去与主节点的数据进行交互。当主节点发生故障的时候，客户端会重更新向sentiel重新要地址，它会将最新的主节点的地址告诉客户端。

## 消息丢失

Redis 主从采用异步复制，意味着 主节点 挂掉时，从节点可能没有收到全部的消息同步。这部分未同步的消息就丢失了。