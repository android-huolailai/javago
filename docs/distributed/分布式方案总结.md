
github地址 https://github.com/doocs/advanced-java

# 高并发

## 数据库

### 1. 数据库动态分库 分表 扩展

DBA 操作

健康的数据库并发量 在 1000

32 个库，32张表。 单库  1500的并发量 ， 1500 * 32 = 48000/s的并发量 + MQ 削峰

分库分表 ，`一次分个够`32 个库 * 32 个表 = 1024 个表 * 500万数据 = 50亿数据

Hash 分库 分表 

### 2. 分库分表之后的ID的生成
1. snowflake
2. leaf 美团 ，获取区间段 + 预热。+ uuid

### 3. 双写迁移方案

在线上系统里面，之前所有写库的地方，增删改操作，**除了对老库增删改，都加上对新库的增删改**，这就是所谓的**双写**，同时写俩库，老库和新库。

新库 与 旧数据 数据差异 -> 需要写导数据工具实现 -> 判断最后修改时间  -> 保证 旧的数据不要覆盖旧的数据 -> 最后检查数据


## 高并发系统的设计

1. 系统拆分 -> dubbo -> 单系统 单数据库
2. 缓存系统 -> redis
3. MQ      -> rocketMQ 
4. 分库分表
5. 读写分离 -> 主库写 从读
6. ES 


## Redis

1. 高并发 高可用
2. 主从复制
3. 哨兵机制

## MQ

1. 幂等性  -> 数据库校验    唯一的id -> 保证 Redis set 的幂等性 
2. 顺序性 -> hash不同的 队列中  -> 单线程 读取队列消息
3. 消息的可靠性传输 -> 持久化，消息确认机制
4. 设计一个MQ ? 伸缩性，集群，分布式吧。持久化吧。队列吧，主题吧。


## 限流

1. 限制 每分钟的请求 通过 计数的方法
2. 令牌桶 漏桶算法 
3. sentinel  

## 分布式锁

zk 注册监听，createNode , or 临时 顺序node 

redis 不断尝试获取锁。


## 分布式事务

1. A 系统先发送一个 prepared 消息到 mq，如果这个 prepared 消息发送失败那么就直接取消操作别执行了；
2. 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 mq 发送确认消息，如果失败就告诉 mq 回滚消息；
3. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；
4. mq 会自动**定时轮询**所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。
5. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。
6. 这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。


## Dubbo
1. 注册中心
2. 负载均衡
3. 代理
4. netty 编解码
5. 
## Zk
1. 分布式锁 创建节点成功的人可以 获得锁 或者 顺序锁的第一个位置
2. 分布式协调 A 系统如何知道B系统的处理结果。A在某个节点注册监听，B处理之后 修改哪个节点。A就会收到监听
3. 元数据或者信息的配置管理


## BigData

1. 统计 电话号码不同的个数 -> bitmap 让 一个号码 占位 1bit. 最后所有 位置为 1 统计就可以了。
2. 判断一个数字在 亿 级中是否存在 -> 位图法 ，让每个数字 占位。 判断 1 是否存在
3. 